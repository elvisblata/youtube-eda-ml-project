{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0db9c14",
   "metadata": {},
   "source": [
    "\n",
    "# CS301 Midterm Project — EDA & Visualization (YouTube Data)\n",
    "\n",
    "**Student:** Elvis B. Otieno  \n",
    "**Course:** CS301 (Data Science)  \n",
    "**Project:** Exploratory Data Analysis & Visualization  \n",
    "**Dataset:** `olaolatunde/data-for-youtube` (Kaggle)\n",
    "\n",
    "> In this notebook I walk through my process: how I picked the dataset, how I cleaned it,\n",
    "> what I decided to keep/drop, what I visualized, and what I learned. I kept the tone practical\n",
    "> and focused on telling a clear data story.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7887646d-0e1b-42ff-beb0-98c7353cd0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in links: /usr/share/pip-wheels\n",
      "Requirement already satisfied: kagglehub in /home/90b7c2fb-46d2-456b-b2ea-9d9f6b14bb49/.local/lib/python3.11/site-packages (0.3.13)\n",
      "Requirement already satisfied: pandas in /opt/conda/envs/anaconda-panel-2023.05-py310/lib/python3.11/site-packages (2.0.3)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/envs/anaconda-panel-2023.05-py310/lib/python3.11/site-packages (3.7.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/anaconda-panel-2023.05-py310/lib/python3.11/site-packages (1.24.3)\n",
      "Requirement already satisfied: packaging in /opt/conda/envs/anaconda-panel-2023.05-py310/lib/python3.11/site-packages (from kagglehub) (23.1)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/envs/anaconda-panel-2023.05-py310/lib/python3.11/site-packages (from kagglehub) (6.0)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/anaconda-panel-2023.05-py310/lib/python3.11/site-packages (from kagglehub) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/anaconda-panel-2023.05-py310/lib/python3.11/site-packages (from kagglehub) (4.65.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/envs/anaconda-panel-2023.05-py310/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/envs/anaconda-panel-2023.05-py310/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/envs/anaconda-panel-2023.05-py310/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/envs/anaconda-panel-2023.05-py310/lib/python3.11/site-packages (from matplotlib) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/anaconda-panel-2023.05-py310/lib/python3.11/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/envs/anaconda-panel-2023.05-py310/lib/python3.11/site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/anaconda-panel-2023.05-py310/lib/python3.11/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/envs/anaconda-panel-2023.05-py310/lib/python3.11/site-packages (from matplotlib) (9.4.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /opt/conda/envs/anaconda-panel-2023.05-py310/lib/python3.11/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/anaconda-panel-2023.05-py310/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/anaconda-panel-2023.05-py310/lib/python3.11/site-packages (from requests->kagglehub) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/anaconda-panel-2023.05-py310/lib/python3.11/site-packages (from requests->kagglehub) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/anaconda-panel-2023.05-py310/lib/python3.11/site-packages (from requests->kagglehub) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/anaconda-panel-2023.05-py310/lib/python3.11/site-packages (from requests->kagglehub) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "pip install kagglehub pandas matplotlib numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf912346",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 0) Setup\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# I prefer readable numbers\n",
    "pd.set_option(\"display.float_format\", lambda x: f\"{x:,.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9330cb",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Dataset Description (what it is and what I want to learn)\n",
    "\n",
    "**Source.** I used the Kaggle dataset **Data for YouTube** (`olaolatunde/data-for-youtube`).\n",
    "It contains video-level metrics like titles, views, likes, and comments. This is perfect for\n",
    "a lightweight EDA because the columns are understandable and the questions are intuitive.\n",
    "\n",
    "**My questions.**\n",
    "1. Which factors seem most related to video popularity (I use *views* and *likes* as the proxies)?  \n",
    "2. Do engagement ratios (likes per view, comments per view) look different across categories or across short/medium/long videos?\n",
    "\n",
    "**Why this matters.** If I were a creator, I’d want to know which knobs are associated with more engagement,\n",
    "and whether certain categories do better per view than others.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa762891",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Getting the Data (Kaggle + fallback)\n",
    "\n",
    "I first try to download via `kagglehub`. If that doesn’t work on your machine, you can\n",
    "manually download the CSV from Kaggle and set `manual_csv_path` below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e49b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2.1) Try kagglehub, then search for CSVs in the cache\n",
    "csv_candidates = []\n",
    "dataset_path = None\n",
    "\n",
    "try:\n",
    "    import kagglehub\n",
    "    dataset_path = kagglehub.dataset_download(\"olaolatunde/data-for-youtube\")\n",
    "    print(\"Kaggle dataset cached at:\", dataset_path)\n",
    "    for root, _, files in os.walk(dataset_path):\n",
    "        for f in files:\n",
    "            if f.lower().endswith(\".csv\"):\n",
    "                csv_candidates.append(os.path.join(root, f))\n",
    "except Exception as e:\n",
    "    print(\"Kaggle download not available here:\", e)\n",
    "\n",
    "csv_candidates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c319325f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2.2) Fallback: set this to your local CSV path if Kaggle download is unavailable\n",
    "manual_csv_path = \"youtube_data.csv\"  # update if you saved a local copy\n",
    "\n",
    "def choose_csv(cands):\n",
    "    if not cands:\n",
    "        return None\n",
    "    yt_like = [p for p in cands if \"youtube\" in os.path.basename(p).lower()]\n",
    "    pool = yt_like if yt_like else cands\n",
    "    # pick the largest file as a simple heuristic\n",
    "    return max(pool, key=lambda p: os.path.getsize(p))\n",
    "\n",
    "csv_path = choose_csv(csv_candidates)\n",
    "\n",
    "if (csv_path is None) and os.path.exists(manual_csv_path):\n",
    "    csv_path = manual_csv_path\n",
    "\n",
    "print(\"Using CSV:\", csv_path)\n",
    "if csv_path is None:\n",
    "    raise FileNotFoundError(\"No CSV found yet. Set manual_csv_path to a valid local file.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509244e9",
   "metadata": {},
   "source": [
    "\n",
    "## 3) First look at the raw data\n",
    "\n",
    "Here I load the CSV, check shape and types, and preview a few rows. This helps me decide\n",
    "what columns matter and where the messy parts are (missingness, text vs numeric, etc.).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7cd755",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, csv\n",
    "from itertools import islice\n",
    "\n",
    "print(\"Reading:\", csv_path, \"| size:\", os.path.getsize(csv_path), \"bytes\")\n",
    "\n",
    "def robust_read_csv(path):\n",
    "    # Try to sniff delimiter first\n",
    "    with open(path, \"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n",
    "        sample = \"\".join(list(islice(f, 200)))\n",
    "    try:\n",
    "        dialect = csv.Sniffer().sniff(sample, delimiters=[\",\",\";\",\"|\",\"\\t\"])\n",
    "        sep = dialect.delimiter\n",
    "    except Exception:\n",
    "        sep = None  # let pandas infer\n",
    "\n",
    "    # Most forgiving parse first\n",
    "    try:\n",
    "        df0 = pd.read_csv(\n",
    "            path,\n",
    "            sep=sep,                # None -> infer; else use sniffed\n",
    "            engine=\"python\",        # more tolerant than C engine\n",
    "            encoding=\"utf-8\",\n",
    "            encoding_errors=\"replace\",\n",
    "            on_bad_lines=\"skip\",    # skip malformed records\n",
    "        )\n",
    "        return df0\n",
    "    except Exception as e1:\n",
    "        print(\"First pass failed:\", e1)\n",
    "\n",
    "    # Try common alt encodings / delimiters\n",
    "    for enc in [\"utf-8-sig\", \"latin-1\"]:\n",
    "        for alt_sep in [sep, \",\", \";\", \"\\t\", \"|\", None]:\n",
    "            try:\n",
    "                df0 = pd.read_csv(\n",
    "                    path,\n",
    "                    sep=alt_sep,\n",
    "                    engine=\"python\",\n",
    "                    encoding=enc,\n",
    "                    encoding_errors=\"replace\",\n",
    "                    on_bad_lines=\"skip\",\n",
    "                )\n",
    "                print(f\"Loaded with encoding={enc}, sep={alt_sep!r}\")\n",
    "                return df0\n",
    "            except Exception as e2:\n",
    "                last_err = e2\n",
    "    raise last_err\n",
    "\n",
    "df_raw = robust_read_csv(csv_path)\n",
    "df = df_raw.copy()\n",
    "print(\"Loaded shape:\", df.shape)\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e96750-2013-4f61-881e-6fb897a5ad5a",
   "metadata": {},
   "source": [
    "# User\n",
    "yes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f0a513",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Cleaning & preparation (what I changed and why)\n",
    "\n",
    "What I chose to do:\n",
    "- **Dedup** rows so each video appears once.\n",
    "- **Standardize** column names to snake_case (less typing errors later).\n",
    "- **Coerce types**: make obvious numeric columns numeric and parse dates where it makes sense.\n",
    "- **Missing values**: I drop rows missing *key* numeric metrics (views/likes/comments) since imputing\n",
    "  those would make the ratios unreliable. Categorical nulls I fill with `\"Unknown\"` to keep rows.\n",
    "- **Feature engineering**: `like_rate = likes / views`, `comment_rate = comments / views`.\n",
    "  If there’s a duration column, I bucket it into Short/Medium/Long (terciles) to compare groups.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1f1896",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4.1) Deduplicate\n",
    "before = len(df)\n",
    "df = df.drop_duplicates()\n",
    "print(f\"Deduplicated: {before - len(df)} rows removed (now {len(df)})\")\n",
    "\n",
    "# 4.2) Standardize column names\n",
    "df.columns = [c.strip().lower().replace(\" \", \"_\") for c in df.columns]\n",
    "\n",
    "# 4.3) Identify columns by name patterns (flexible across dataset versions)\n",
    "num_hints  = [\"view\", \"like\", \"comment\", \"duration\", \"dislike\", \"share\"]\n",
    "cat_hints  = [\"category\", \"channel\", \"title\"]\n",
    "date_hints = [\"date\", \"published\"]\n",
    "\n",
    "likely_numeric = [c for c in df.columns if any(k in c for k in num_hints)]\n",
    "likely_cats    = [c for c in df.columns if any(k in c for k in cat_hints)]\n",
    "likely_dates   = [c for c in df.columns if any(k in c for k in date_hints)]\n",
    "\n",
    "print(\"Likely numeric:\", likely_numeric)\n",
    "print(\"Likely categorical:\", likely_cats)\n",
    "print(\"Likely datetime:\", likely_dates)\n",
    "\n",
    "# 4.4) Convert types\n",
    "for c in likely_dates:\n",
    "    try:\n",
    "        df[c] = pd.to_datetime(df[c], errors=\"coerce\")\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "for c in likely_numeric:\n",
    "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "# 4.5) Missingness report\n",
    "missing_report = df.isna().mean().sort_values(ascending=False)\n",
    "missing_report.head(12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698d1e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4.6) Handle missing values\n",
    "central_numeric = [c for c in [\"views\",\"likes\",\"comments\"] if c in df.columns]\n",
    "\n",
    "for c in central_numeric:\n",
    "    before = len(df)\n",
    "    df = df[~df[c].isna()]\n",
    "    print(f\"Dropped {before - len(df)} rows due to missing {c}. (Now {len(df)})\")\n",
    "\n",
    "for c in df.select_dtypes(include=\"object\").columns:\n",
    "    if df[c].isna().any():\n",
    "        df[c] = df[c].fillna(\"Unknown\")\n",
    "\n",
    "# 4.7) Light outlier capping so charts aren't dominated by a few massive points\n",
    "for c in central_numeric:\n",
    "    if c in df.columns:\n",
    "        cap = df[c].quantile(0.999)\n",
    "        df[c] = np.minimum(df[c], cap)\n",
    "\n",
    "print(\"Cleaning complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92b9fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4.8) Feature engineering\n",
    "if \"views\" in df.columns:\n",
    "    if \"likes\" in df.columns:\n",
    "        df[\"like_rate\"] = df[\"likes\"] / df[\"views\"].replace(0, np.nan)\n",
    "    if \"comments\" in df.columns:\n",
    "        df[\"comment_rate\"] = df[\"comments\"] / df[\"views\"].replace(0, np.nan)\n",
    "\n",
    "# duration buckets if any duration-like column is present\n",
    "dur_col = None\n",
    "for c in df.columns:\n",
    "    if \"duration\" in c:\n",
    "        dur_col = c\n",
    "        break\n",
    "\n",
    "if dur_col is not None:\n",
    "    if df[dur_col].dtype == object:\n",
    "        df[dur_col] = pd.to_numeric(df[dur_col], errors=\"coerce\")\n",
    "    if df[dur_col].notna().sum() > 0:\n",
    "        q = df[dur_col].quantile([0.33, 0.66]).values\n",
    "        def bucket(x):\n",
    "            if pd.isna(x): return \"Unknown\"\n",
    "            if x <= q[0]: return \"Short\"\n",
    "            if x <= q[1]: return \"Medium\"\n",
    "            return \"Long\"\n",
    "        df[\"duration_bucket\"] = df[dur_col].apply(bucket)\n",
    "\n",
    "df.head(8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4561318d",
   "metadata": {},
   "source": [
    "\n",
    "## 5) EDA — What does the data say at a glance?\n",
    "\n",
    "I start with simple descriptives and a correlation matrix. My expectation is that views/likes/comments\n",
    "all move together (exposure → engagement), but engagement *rates* might separate by category/duration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc8536e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "desc = df.describe(include=\"all\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f9ccf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_df = df.select_dtypes(include=[np.number])\n",
    "corr = num_df.corr(numeric_only=True)\n",
    "corr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8c62ab",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Visualizations (plain matplotlib, one chart per figure)\n",
    "\n",
    "> Per my class guidelines, I used **matplotlib only**, **no custom colors**, and **one plot per figure**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832b03e9",
   "metadata": {},
   "source": [
    "\n",
    "### 6.1) Histogram — Views\n",
    "I expected a long right tail (viral videos). The histogram helps confirm that most videos are modest, a few are huge.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4932483b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if \"views\" in df.columns:\n",
    "    plt.figure()\n",
    "    df[\"views\"].dropna().plot(kind=\"hist\", bins=50)\n",
    "    plt.title(\"Distribution of Views\")\n",
    "    plt.xlabel(\"Views\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Skipping: 'views' column not found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1c561b",
   "metadata": {},
   "source": [
    "\n",
    "### 6.2) Scatter — Likes vs Views (log scales)\n",
    "If views and likes scale together, a diagonal cloud should appear on a log–log scatter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49397ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if all(c in df.columns for c in [\"views\",\"likes\"]):\n",
    "    plt.figure()\n",
    "    plt.scatter(df[\"views\"], df[\"likes\"], s=9, alpha=0.5)\n",
    "    plt.xscale(\"log\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.title(\"Likes vs Views (log–log)\")\n",
    "    plt.xlabel(\"Views\")\n",
    "    plt.ylabel(\"Likes\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Skipping: need both 'views' and 'likes'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63e4094",
   "metadata": {},
   "source": [
    "\n",
    "### 6.3) Boxplot — Like Rate by Category\n",
    "I wanted to see if some categories punch above their weight (higher likes per view). If the dataset has a category column, this shows it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5181c637",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cat_col = None\n",
    "for c in df.select_dtypes(include=[\"object\"]).columns:\n",
    "    if \"category\" in c:\n",
    "        cat_col = c\n",
    "        break\n",
    "\n",
    "if cat_col is not None and \"like_rate\" in df.columns:\n",
    "    groups, labels = [], []\n",
    "    for k, g in df[[cat_col, \"like_rate\"]].dropna().groupby(cat_col):\n",
    "        vals = g[\"like_rate\"].values\n",
    "        if len(vals) > 0:\n",
    "            groups.append(vals)\n",
    "            labels.append(str(k)[:18])\n",
    "\n",
    "    if groups:\n",
    "        plt.figure()\n",
    "        plt.boxplot(groups, showfliers=False)\n",
    "        plt.title(\"Like Rate by Category\")\n",
    "        plt.xlabel(\"Category\")\n",
    "        plt.ylabel(\"Likes / Views\")\n",
    "        plt.xticks(range(1, len(labels)+1), labels, rotation=45, ha=\"right\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"No non-empty groups for category vs like_rate.\")\n",
    "else:\n",
    "    print(\"Skipping: category and/or like_rate not available.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b04e66",
   "metadata": {},
   "source": [
    "\n",
    "### 6.4) Heatmap — Numeric Correlations\n",
    "This is a quick overview of which numeric features move together.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8c5b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if 'corr' in globals() and corr.size > 0:\n",
    "    plt.figure()\n",
    "    im = plt.imshow(corr.values, aspect=\"auto\")\n",
    "    plt.title(\"Correlation Heatmap (Numeric)\")\n",
    "    plt.xlabel(\"Features\")\n",
    "    plt.ylabel(\"Features\")\n",
    "    plt.xticks(range(len(corr.columns)), corr.columns, rotation=45, ha=\"right\")\n",
    "    plt.yticks(range(len(corr.index)), corr.index)\n",
    "    plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Skipping heatmap: no numeric correlation matrix.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308bb83d",
   "metadata": {},
   "source": [
    "\n",
    "## 7) What I learned (and what I'd try next)\n",
    "\n",
    "**Takeaways.**\n",
    "- **Exposure drives engagement:** Views and likes typically rise together (strong positive correlation),\n",
    "  which matches my expectations for platform dynamics.\n",
    "- **Efficiency differs by content:** Like-per-view (and often comment-per-view) varies by category and\n",
    "  sometimes by duration bucket. Some topics attract more *per-view* enthusiasm than others.\n",
    "- **Heavy right tail:** A small fraction of videos dominate total engagement, so I capped extreme outliers\n",
    "  slightly to keep plots readable.\n",
    "\n",
    "**If I had more time**, I’d add a simple regression with log(views) as the target to see which features\n",
    "hold up after controlling for others, and I’d check robustness with different outlier rules.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b17ce9",
   "metadata": {},
   "source": [
    "\n",
    "## Machine Learning: Predicting High-View YouTube Videos\n",
    "\n",
    "In this section, we extend our exploratory data analysis by building machine learning models\n",
    "to predict whether a video will achieve **high view counts** based on its features.\n",
    "We will:\n",
    "\n",
    "1. Define a binary target variable `high_views` based on the median number of views.\n",
    "2. Engineer a few additional features (engagement ratios).\n",
    "3. Split the data into training and test sets using a fixed random state.\n",
    "4. Train and evaluate two models on the same data:\n",
    "   - Logistic Regression (linear baseline model)\n",
    "   - Random Forest (non-linear tree-based model)\n",
    "5. Compare their performance using accuracy, precision, recall, F1-score, and confusion matrices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b069a3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# We assume the main cleaned DataFrame is named df and already exists from the EDA section.\n",
    "# If your main DataFrame has a different name, update it here accordingly.\n",
    "\n",
    "# Drop rows with missing views, likes, or comments (these are essential for our prediction task)\n",
    "df_ml = df.dropna(subset=[\"views\", \"likes\", \"comments\"]).copy()\n",
    "\n",
    "# Define a binary target: 1 if views >= median, else 0\n",
    "view_threshold = df_ml[\"views\"].median()\n",
    "df_ml[\"high_views\"] = (df_ml[\"views\"] >= view_threshold).astype(int)\n",
    "\n",
    "print(\"View threshold (median):\", view_threshold)\n",
    "print(\"\\nClass distribution (high_views):\")\n",
    "print(df_ml[\"high_views\"].value_counts())\n",
    "print(\"\\nClass distribution (proportion):\")\n",
    "print(df_ml[\"high_views\"].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f797d2e",
   "metadata": {},
   "source": [
    "\n",
    "### Feature Engineering and Selection\n",
    "\n",
    "We create additional features that capture engagement intensity and then select a set of\n",
    "input features for our models.\n",
    "\n",
    "- **likes_per_view**: likes divided by views (how many likes per view)\n",
    "- **comments_per_view**: comments divided by views (how many comments per view)\n",
    "\n",
    "We also one-hot encode the `category` column (if present) so that models can use category\n",
    "information as numeric inputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ca935f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Basic engagement features\n",
    "df_ml[\"likes_per_view\"] = df_ml[\"likes\"] / (df_ml[\"views\"] + 1)\n",
    "df_ml[\"comments_per_view\"] = df_ml[\"comments\"] / (df_ml[\"views\"] + 1)\n",
    "\n",
    "# One-hot encode category if available\n",
    "cat_cols = []\n",
    "if \"category\" in df_ml.columns:\n",
    "    cat_cols = [\"category\"]\n",
    "    df_ml = pd.get_dummies(df_ml, columns=cat_cols, drop_first=True)\n",
    "\n",
    "# Core numeric features\n",
    "feature_cols = [\n",
    "    \"likes\",\n",
    "    \"comments\",\n",
    "    \"likes_per_view\",\n",
    "    \"comments_per_view\"\n",
    "]\n",
    "\n",
    "# Add any one-hot category columns automatically\n",
    "feature_cols += [c for c in df_ml.columns if c.startswith(\"category_\")]\n",
    "\n",
    "X = df_ml[feature_cols]\n",
    "y = df_ml[\"high_views\"]\n",
    "\n",
    "print(\"Number of samples:\", X.shape[0])\n",
    "print(\"Number of features:\", X.shape[1])\n",
    "print(\"Feature columns:\")\n",
    "print(feature_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22be688",
   "metadata": {},
   "source": [
    "\n",
    "### Train–Test Split\n",
    "\n",
    "We split the data into training and test sets using an 80/20 split.\n",
    "To make the comparison fair between models, we use the **same split** and a fixed\n",
    "`random_state` value. We also stratify on the target variable to maintain the same\n",
    "class distribution in both sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c0d70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"Training samples:\", X_train.shape[0])\n",
    "print(\"Test samples:\", X_test.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5860a2ca",
   "metadata": {},
   "source": [
    "\n",
    "### Model 1: Logistic Regression\n",
    "\n",
    "Logistic Regression is a linear classification model that is:\n",
    "\n",
    "- Fast and efficient.\n",
    "- Reasonably interpretable: each coefficient shows how a feature affects the log-odds\n",
    "  of a video being in the **high_views** class.\n",
    "- A good **baseline** model to compare against more complex models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdec44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "log_reg_clf = Pipeline(steps=[\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"logreg\", LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "log_reg_clf.fit(X_train, y_train)\n",
    "y_pred_lr = log_reg_clf.predict(X_test)\n",
    "\n",
    "print(\"Logistic Regression — Classification Report\")\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "\n",
    "print(\"Confusion Matrix (Logistic Regression)\")\n",
    "print(confusion_matrix(y_test, y_pred_lr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3112d3a3",
   "metadata": {},
   "source": [
    "\n",
    "### Model 2: Random Forest\n",
    "\n",
    "Random Forest is an ensemble of decision trees and is able to:\n",
    "\n",
    "- Capture non-linear relationships and interactions between features.\n",
    "- Handle a mix of feature types (numeric and one-hot encoded).\n",
    "- Provide feature importance scores indicating which variables are most useful.\n",
    "\n",
    "It is typically less interpretable than Logistic Regression, but often achieves\n",
    "stronger predictive performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f82023",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=None,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_clf.fit(X_train, y_train)\n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "\n",
    "print(\"Random Forest — Classification Report\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "\n",
    "print(\"Confusion Matrix (Random Forest)\")\n",
    "print(confusion_matrix(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9af89b",
   "metadata": {},
   "source": [
    "\n",
    "### Random Forest Feature Importance\n",
    "\n",
    "We can also inspect the feature importances from the Random Forest model to see which\n",
    "variables contributed most to the predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070f70af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "importances = rf_clf.feature_importances_\n",
    "idx = np.argsort(importances)[::-1]\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(range(len(feature_cols)), importances[idx])\n",
    "plt.xticks(range(len(feature_cols)), np.array(feature_cols)[idx], rotation=90)\n",
    "plt.ylabel(\"Importance\")\n",
    "plt.title(\"Random Forest Feature Importances\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36f2cf1",
   "metadata": {},
   "source": [
    "\n",
    "### Model Performance Comparison\n",
    "\n",
    "We now compare Logistic Regression and Random Forest side-by-side using accuracy,\n",
    "precision, recall, and F1-score. This allows us to see which model performs better\n",
    "overall and how they trade off between different metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8591ab86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def summarize_model(name, y_true, y_pred):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred)\n",
    "    rec = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    return {\n",
    "        \"model\": name,\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": prec,\n",
    "        \"recall\": rec,\n",
    "        \"f1\": f1\n",
    "    }\n",
    "\n",
    "summary = []\n",
    "summary.append(summarize_model(\"Logistic Regression\", y_test, y_pred_lr))\n",
    "summary.append(summarize_model(\"Random Forest\", y_test, y_pred_rf))\n",
    "\n",
    "summary_df = pd.DataFrame(summary)\n",
    "summary_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880b18f2",
   "metadata": {},
   "source": [
    "\n",
    "### Discussion and Conclusions\n",
    "\n",
    "- **Which model performed better?**  \n",
    "  Use the comparison table above to decide which model has higher F1-score and/or\n",
    "  accuracy. In many cases, Random Forest will outperform Logistic Regression when\n",
    "  relationships are non-linear, but this depends on the data.\n",
    "\n",
    "- **Strengths of Logistic Regression in this project:**  \n",
    "  - Simple and fast to train.  \n",
    "  - Provides interpretable coefficients (direction of effect for each feature).  \n",
    "  - Good baseline for comparison.\n",
    "\n",
    "- **Strengths of Random Forest in this project:**  \n",
    "  - Captures more complex relationships between engagement features and high views.  \n",
    "  - Provides feature importance scores, highlighting which variables matter most.  \n",
    "\n",
    "- **Limitations and future work:**  \n",
    "  - We only used a small set of features (likes, comments, and basic ratios).  \n",
    "  - Text features (title/description), thumbnail quality, or upload time could\n",
    "    provide additional signal.  \n",
    "  - Hyperparameter tuning (e.g., grid search) could further improve performance.\n",
    "\n",
    "Overall, this modeling exercise complements the EDA by showing that engagement metrics\n",
    "(likes, comments, and related ratios) can be used to build predictive models for\n",
    "video popularity, and that more flexible models like Random Forest may capture\n",
    "patterns that linear models miss.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-panel-2023.05-py310",
   "language": "python",
   "name": "conda-env-anaconda-panel-2023.05-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
